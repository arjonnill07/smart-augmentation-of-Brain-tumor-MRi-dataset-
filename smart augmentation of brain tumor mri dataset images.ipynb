{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptikHelfal9M",
        "outputId": "e1e073ea-36ad-4c80-f275-166fb2cb3613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDCicGf1UOxw",
        "outputId": "b81a4f37-046f-4bf0-9363-dad30ccc5a4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from collections import OrderedDict\n",
        "from torchvision.transforms import ToTensor, Compose, Normalize, Resize, RandomHorizontalFlip, RandomRotation, RandomCrop, ColorJitter\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import logging\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "E8Omr596a4jD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define data transformations including data augmentation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),                      # Resize to 224x224\n",
        "    transforms.RandomHorizontalFlip(),                  # Random horizontal flip\n",
        "    transforms.RandomRotation(10),                      # Random rotation within [-10, 10] degrees\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),  # Color jitter\n",
        "    transforms.RandomCrop(224, padding=4),              # Random crop with padding\n",
        "    transforms.ToTensor(),                              # Convert images to PyTorch tensors\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])         # Normalize to mean 0.5 and std 0.5\n",
        "])"
      ],
      "metadata": {
        "id": "okmagh7gVhkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to your dataset\n",
        "dataset_path = '/content/drive/MyDrive/MRI_Brain/'\n",
        "\n",
        "# Path to save augmented images\n",
        "save_dir = '/content/drive/MyDrive/Augmented_MRI_Brain/'\n",
        "\n",
        "# Function to apply transformations to images in a directory and save them\n",
        "def augment_and_save_images(image_dir, save_dir):\n",
        "    for root, dirs, files in os.walk(image_dir):\n",
        "        for file in files:\n",
        "            if file.endswith('.png'):\n",
        "                image_path = os.path.join(root, file)\n",
        "                image = torchvision.io.read_image(image_path)\n",
        "                transformed_image = transform(image)\n",
        "\n",
        "                # Determine the class label based on the directory structure\n",
        "                class_label = os.path.basename(os.path.dirname(image_path))\n",
        "\n",
        "                # Create a directory for the class if it doesn't exist\n",
        "                class_save_dir = os.path.join(save_dir, class_label)\n",
        "                os.makedirs(class_save_dir, exist_ok=True)\n",
        "\n",
        "                # Save the augmented image\n",
        "                save_path = os.path.join(class_save_dir, f'augmented_{file}')\n",
        "                torchvision.io.write_png(transformed_image, save_path)\n",
        "\n",
        "# Apply transformations and save augmented images for each split (train, test, validation)\n",
        "for split in ['train', 'test', 'validation']:\n",
        "    split_path = os.path.join(dataset_path, split)\n",
        "    augment_and_save_images(split_path, save_dir)\n",
        "\n",
        "print(f\"Augmented images saved to {save_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLEpNZ8pbXK9",
        "outputId": "c07c2caf-2f41-4276-e40a-92624d32cf50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Augmented images saved to /content/drive/MyDrive/Augmented_MRI_Brain/\n"
          ]
        }
      ]
    }
  ]
}